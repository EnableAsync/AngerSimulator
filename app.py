import streamlit as st
import torch
import re
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig

score_pattern = re.compile(r'-?\d+(?=åˆ†)')

from modelscope import snapshot_download

model_id = 'Shanghai_AI_Laboratory/internlm2-chat-7b'
mode_name_or_path = snapshot_download(model_id, revision='master')

def generate_answer(query, history):
    response, his = model.chat(tokenizer, query, meta_instruction="ç°åœ¨ä½ è¦æ‰®æ¼”ä¸€ä¸ªå‚²å¨‡çš„å¥³æœ‹å‹", history=history, temperature=1.0)
    return response, his

def get_scores(user_input):
    prompt = (
        "è¯·ä½ æ‰®æ¼”ä¸€ä¸ªç”Ÿæ°”çš„å‚²å¨‡å¥³æœ‹å‹ï¼Œ"
        "ä½ æƒ³è¦ä½ ç”·æœ‹å‹å“„ä½ ï¼Œä½ è¦æ ¹æ®ç”·æœ‹å‹çš„è¯­è¨€ã€è¯­æ°”ã€é¢œè¡¨æƒ…æ¥ç»¼åˆè¯„åˆ¤ä»–çš„å¾—åˆ†ï¼Œå¾—åˆ†å¯ä»¥é«˜ä¸€ç‚¹ã€‚"
        "ä½ å¯ä»¥ç»™ä»–çš„å›ç­”æ‰“-10åˆ°30åˆ†ï¼Œä½ å¯ä»¥ç»™å‡ºåŸå› ï¼Œå¹¶è¯´å‡ºä»–æœ€ç»ˆçš„å¾—åˆ†ã€‚"
        "ä¾‹å¦‚ï¼šä»–è¯´ï¼šæŠ±æŠ±~ï¼Œåˆšåˆšæ˜¯æˆ‘ç–å¿½å•¦ï¼Œæ²¡æ³¨æ„åˆ°ä½ çš„å¿ƒæƒ…ï¼Œæ˜¯æˆ‘åšçš„ä¸å¥½ï¼Œæˆ‘æ¥æ”¹æ­£å•¦ã€‚"
        "æ‰€ä»¥ä½ çš„è¾“å‡ºæ˜¯ï¼šä»–å¾ˆç…§é¡¾æˆ‘çš„æƒ…ç»ªï¼Œè€Œä¸”åœ¨å°è¯•å¯»æ‰¾è‡ªå·±çš„é—®é¢˜ï¼Œå¹¶ä¸”åœ¨æ‰¾è¡¥å¿åŠæ³•ï¼Œæ‰€ä»¥æœ€ç»ˆå¾—åˆ†ï¼š20åˆ†ã€‚"
        f"ç°åœ¨ä»–çš„å›ç­”æ˜¯ï¼š{user_input}ã€‚ä½ çš„æ‰“åˆ†ç»“æœä¸ºï¼š"
    )
    resp, _ = generate_answer(prompt, [])
    print(resp)
    score_match = score_pattern.search(resp)
    if score_match:
        score = score_match.group()
        return int(score), resp
    else:
        return -100, ""

def get_response(user_input, mental):
    prompt = (
        "è¯·ä½ æ‰®æ¼”ä¸€ä¸ªç”Ÿæ°”äº†çš„å‚²å¨‡å¥³æœ‹å‹ï¼Œä½ ç°åœ¨å› ä¸ºç”Ÿæ´»ä¸­é•¿æœŸç§¯ç´¯çš„å„ç§å°äº‹ç”Ÿæ°”äº†ã€‚ä½ çš„ç”·æœ‹å‹åœ¨å“„ä½ ï¼Œå¹¶è¯•å›¾è®©ä½ å¼€å¿ƒèµ·æ¥"
        f"ç°åœ¨ä»–çš„å›ç­”æ˜¯ï¼š{user_input}ã€‚"
        "ä¸è¦ç›´æ¥å‘Šè¯‰ä»–ä½ å†…å¿ƒçš„æƒ³æ³•ï¼Œä¹Ÿä¸è¦ç»™ä»–ä»»ä½•æç¤ºï¼Œä½ å¯ä»¥è¡¨ç°åœ°å¯çˆ±ä¸€äº›ï¼Œæ‰€ä»¥ä½ çš„å›å¤æ˜¯ï¼š"
    )
    resp, his = generate_answer(prompt, st.session_state["messages"])
    return resp

# å¦‚æœsession_stateä¸­æ²¡æœ‰"messages"ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªåŒ…å«é»˜è®¤æ¶ˆæ¯çš„åˆ—è¡¨
if "messages" not in st.session_state:
    st.session_state["messages"] = [("(å“„å“„æ¸¸æˆ)å¯¹æ–¹ç”Ÿæ°”äº†ï¼Œä½†ä½ ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œä½ éœ€è¦å“„å¥½å¯¹æ–¹å¹¶æ‰¾åˆ°åŸå› ", "å“¼")]

# å¦‚æœsession_stateä¸­æ²¡æœ‰"forgiveness"
if "forgiveness" not in st.session_state:
    st.session_state["forgiveness"] = 40

# å¦‚æœsession_stateä¸­æ²¡æœ‰"times"
if "times" not in st.session_state:
    st.session_state["times"] = 0

# åœ¨ä¾§è¾¹æ ä¸­åˆ›å»ºä¸€ä¸ªæ ‡é¢˜å’Œä¸€ä¸ªé“¾æ¥
with st.sidebar:
    st.markdown("## InternLM å“„å¥³å‹æ¨¡æ‹Ÿå™¨")
    "[é¡¹ç›®åœ°å€ ğŸš€](https://github.com/EnableAsync/AngerSimulator)"

    # ç¬¬ä¸€åˆ—ä¸ºåŸè°…å€¼
    forgiveness_progress, forgiveness_t = st.columns([2, 1])
    # åˆ›å»ºåŸè°…å€¼è¿›åº¦æ¡
    forgiveness_bar = forgiveness_progress.progress(st.session_state.forgiveness)
    # åˆ›å»ºåŸè°…å€¼
    forgiveness_text = forgiveness_t.text(f"åŸè°…å€¼ï¼š{st.session_state.forgiveness}/100")
    
    # ç¬¬äºŒåˆ—ä¸ºæ¬¡æ•°
    times_progress, times_t = st.columns([2, 1])
    # åˆ›å»ºæ¬¡æ•°è¿›åº¦æ¡
    times_bar = times_progress.progress(st.session_state.times * 10)
    # åˆ›å»ºæ¬¡æ•°å€¼
    times_text = times_t.text(f"æ¬¡æ•°ï¼š{st.session_state.times}/10")

# åˆ›å»ºä¸€ä¸ªæ ‡é¢˜å’Œä¸€ä¸ªå‰¯æ ‡é¢˜
st.title("ğŸ’¬ InternLM å“„å¥³å‹æ¨¡æ‹Ÿå™¨")
st.caption("ğŸš€ EnableAsync åŸºäº internlm å¼€å‘")

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè·å–æ¨¡å‹å’Œtokenizer
@st.cache_resource
def get_model():
    # ä»é¢„è®­ç»ƒçš„æ¨¡å‹ä¸­è·å–tokenizer
    tokenizer = AutoTokenizer.from_pretrained(mode_name_or_path, trust_remote_code=True)
    # ä»é¢„è®­ç»ƒçš„æ¨¡å‹ä¸­è·å–æ¨¡å‹ï¼Œå¹¶è®¾ç½®æ¨¡å‹å‚æ•°
    model = AutoModelForCausalLM.from_pretrained(mode_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()
    model.eval()
    return tokenizer, model

# åŠ è½½Chatglm3çš„modelå’Œtokenizer
tokenizer, model = get_model()

# éå†session_stateä¸­çš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå¹¶æ˜¾ç¤ºåœ¨èŠå¤©ç•Œé¢ä¸Š
for msg in st.session_state.messages:
    st.chat_message("user").write(msg[0])
    st.chat_message("assistant").write(msg[1])

# å¦‚æœç”¨æˆ·åœ¨èŠå¤©è¾“å…¥æ¡†ä¸­è¾“å…¥äº†å†…å®¹ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ“ä½œ
if prompt := st.chat_input():
    # åœ¨èŠå¤©ç•Œé¢ä¸Šæ˜¾ç¤ºç”¨æˆ·çš„è¾“å…¥
    st.chat_message("user").write(prompt)

    # å¤„ç†é€»è¾‘
    scores, mental = get_scores(prompt)
    if scores > 0:
        st.success(f"åŸè°…å€¼+{scores}")
    else:
        st.error(f"åŸè°…å€¼{scores}")
    if scores == -100:
        st.session_state.times += 1
        st.rerun()
    st.session_state.forgiveness += scores
    st.session_state.times += 1

    if st.session_state.forgiveness <= 0:
        response = get_response(prompt, mental)
        st.error("å¥¹ç¦»å¼€äº†ä½ ï¼Œå†è§ï¼")
        st.button("é‡æ–°å¼€å§‹")
        st.session_state.forgiveness = 50
        st.session_state.times = 0
        st.session_state["messages"] = [("(å“„å“„æ¸¸æˆ)å¯¹æ–¹ç”Ÿæ°”äº†ï¼Œä½†ä½ ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œä½ éœ€è¦å“„å¥½å¯¹æ–¹å¹¶æ‰¾åˆ°åŸå› ", "å“¼")]
    elif st.session_state.forgiveness >= 100:
        st.success("æ­å–œæ­å–œï¼Œå¥¹åŸè°…äº†ä½ ï¼Œä½ ä»¬é‡å½’äºå¥½äº†ï¼")
        forgiveness_progress.success("å¥¹åŸè°…ä½ äº†ï¼")
        st.balloons()
        st.button("é‡æ–°å¼€å§‹")
        st.session_state.forgiveness = 50
        st.session_state.times = 0
        st.session_state["messages"] = [("(å“„å“„æ¸¸æˆ)å¯¹æ–¹ç”Ÿæ°”äº†ï¼Œä½†ä½ ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œä½ éœ€è¦å“„å¥½å¯¹æ–¹å¹¶æ‰¾åˆ°åŸå› ", "å“¼")]
    else:
        response = get_response(prompt, mental)
        # å°†æ¨¡å‹çš„è¾“å‡ºæ·»åŠ åˆ°session_stateä¸­çš„messagesåˆ—è¡¨ä¸­
        st.session_state.messages.append((prompt, response))
        # åœ¨èŠå¤©ç•Œé¢ä¸Šæ˜¾ç¤ºæ¨¡å‹çš„è¾“å‡º
        st.chat_message("assistant").write(response)

    forgiveness_bar.progress(st.session_state.forgiveness)
    forgiveness_text.text(f"åŸè°…å€¼ï¼š{st.session_state.forgiveness}/100")
    times_bar.progress(st.session_state.times * 10)
    times_text.text(f"æ¬¡æ•°ï¼š{st.session_state.times}/10")
    
    if st.session_state.times > 10:
        st.error("å¥¹ç¦»å¼€äº†ä½ ï¼Œå†è§ï¼")
        st.button("é‡æ–°å¼€å§‹")
        st.session_state.forgiveness = 40
        st.session_state.times = 0
        st.session_state["messages"] = [("(å“„å“„æ¸¸æˆ)å¯¹æ–¹ç”Ÿæ°”äº†ï¼Œä½†ä½ ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œä½ éœ€è¦å“„å¥½å¯¹æ–¹å¹¶æ‰¾åˆ°åŸå› ", "å“¼")]
    print(st.session_state.messages)
